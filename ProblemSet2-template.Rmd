---
title: "Analysis on key factors affecting life satisfaction"
author: "Woolim Kim, Yena Joo, Guemin Kim"
date: "Oct 19, 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
library(dplyr)
library(tidyverse)
data <- read_csv("gss.csv")
```

# Analysis on key factors affecting life satisfaction

<!-- ### Woolim Kim, Yena Joo, Guemin Kim -->
<!-- ### Oct 19, 2020 -->

## Abstract
*Here is where you give a brief (one paragraph overview of your entire paper). This should include some background/introduction, some methodology, results and conclusions.*

We use the 2017 General Social Survey(GSS) data to study the response of people in Canada's life satisfactions to multiple factors. The target population includes all non-institutionalized persons 15 years of age and older, living in the 10 provinces of Canada. The frame population is everyone who is registered combining both landline and cellular with Statistics Canada’s address registers, and the sampled population is whoever is reached via telephone. The target population was divided into 27 strata by geographic areas, and simple random sampling without replacement of records was performed in each stratum (which means, from each stratum/group, everyone has an equal probability of being chosen). The objective of the analysis is to find and analyze some potential factors that affect life satisfaction, and to observe the most significant factor among them. Through the analysis, We find a strong linear relationship between self rated mental health and life satisfaction rate. People who rate themselves as "mentally healthy" are relatively more satisfied with their lives. The analysis also shows a linear relationship between physical health and life satisfaction. On the other hand, there is no overall effects of hours worked on life satisfaction level. 
Together, these results suggest that no matter how much the income or working hours are, the most important factor that decides people's life satisfaction level is their mental and physical health. 

## Introduction
*Here is where you should give insight into the setting and introduce the goal of the analysis. Here you can introduce ideas and basic concepts regarding the study setting and the potential model. Again, this is the introduction, so you should be explaining the importance of the work that is ahead and hopefully build some suspense for the reader. You can also highlight what will be included in the subsequent sections.*

There are many factors that determine one's well being and satisfaction of life. It could be health condition, economic status, relationships, religion, or any other element one would value or prioritize.   
Particularly, in these uncertain and unprecedented times caused by the COVID-19 pandemic, many people across the world are feeling more stressed due to the changes that the pandemic has brought into their lives and those concerns negatively influence their own well being.
Therefore, as the ongoing COVID-19 crisis reminds us of the importance of well being, our group decided to investigate and determine some factors that influence one's well being and satisfaction of life.

Throughout this report, we are going to determine and analyze some potential factors that affect one's life satisfaction, as well as to identify the most significant factor among them.  
To be more specific, in the following sections, we will use statistical methods to build a regression model of life satisfaction score by potential factors, and interpret the regression output to find relationships between the life satisfaction score and potential factors.  
This process includes cleaning the given data into a simpler, but efficient version, linear regression modelling, graphical visualizations and interpretations of the outputs.

## Data
*Introduce the data, explain why it was selected. Make sure to comment on important features and highlight any potential drawbacks to the data.*

The data set we chose for this assignment contains responses of the General Social Survey conducted in 2017. The contents of the survey include some characteristics of diverse families in Canada, their socio-economic status, as well as other subjective information such as the respondent's life satisfaction and health conditions. 

Since we want to identify some key factors affecting one's life satisfaction as mentioned previously, the focus of our analysis will be "Health and subjective well-being". 

The reason for choosing the 2017 GSS is because it is the most recent^[As it is stated in the documentation of the GSS, one of the primary objectives of the General Social Survey is to monitor the well being of Canadians over time.
As a result, every survey conducted so far contain the responses related to the questions asking for the respondents' well being, and the 2017 GSS is the most recent survey with such responses.] survey that includes  the "Health and subjective well being" topic.

One of the characteristics of our data set is that the majority of the variables are categorical. However, some drawbacks of using such data is that there is a limit to the kinds of statistical analysis that we can use with our data, as well as numerical operations or quantitative analysis cannot be performed on such data.  
Not only this, but there are number of columns in our data set with too many NAs in them, and this indicates that many of observations in certain variables are not available or missing. If we want to use such variables in our analysis, we would first need to exclude those 'NA' observations from our data; however, any results drawn from the data could possibly be biased or misleading due to the small number of observations available. 

Since the original data set contains too many variables that are not necessary, we are going to clean the data set prior to analysis by removing them.

```{r include = F, echo = F, warning = F, message = F}
# life satisfaction data with some potential factors
life_satisfaction_data <- data %>% 
  select(caseid, age, sex, feelings_life, self_rated_health, self_rated_mental_health, 
         income_family, average_hours_worked) %>% 
  # mutate categorical values in self_rated_health into numerical scores
  mutate(self_rated_health = case_when(self_rated_health == "Excellent" ~ 5, 
                                       self_rated_health == "Very good" ~ 4, 
                                       self_rated_health == "Good" ~ 3, 
                                       self_rated_health == "Fair" ~ 2, 
                                       self_rated_health == "Poor" ~1, 
                                       self_rated_health == "Don't know" ~ 0)) %>%
  # mutate categorical values in self_rated_mental_health into numerical scores
  mutate(self_rated_mental_health = case_when(self_rated_mental_health == "Excellent" ~ 5, 
                                              self_rated_mental_health == "Very good" ~ 4, 
                                              self_rated_mental_health == "Good" ~ 3, 
                                              self_rated_mental_health == "Fair" ~ 2, 
                                              self_rated_mental_health == "Poor" ~1, 
                                              self_rated_mental_health == "Don't know" ~ 0)) %>%
  filter(self_rated_health != 0, self_rated_mental_health != 0, 
         average_hours_worked != "Don't know") %>%
  rename(ID = caseid, satisfaction_score = feelings_life, family_income = income_family, work_hours = average_hours_worked)
```

Here is our newly created data:
```{r echo = F, warning = F, message = F}
head(life_satisfaction_data)
```

Our data contains 8 variables: ID, age, sex, satisfaction_score, self_rated_health, self_rated_mental_health, family_income, and work_hours.  
Detailed descriptions on variables are provided in the footnote^[* satisfaction_score indicates the life satisfaction score on a scale of 0(very dissatisfied) to 10(very satisfied).  
\    \    \ * self_rated_health and self_rated_mental health are the physical and mental health ratings, respectively,  
\    \    \ on a scale of 1(poor) to 5(Excellent) given by the respondent.  
\    \    \ * work_hours indicates the average number of hours worked per week.].

Since we want to observe how the life satisfaction score is related to potential factors such as health or financial conditions, the response variable of our analysis will be satisfaction_score and the predictors will be the potential factors: self_rated_health, self_rated_mental_health, family_income, and work_hours.


\newpage
## Model

Introduce the selected model here. It is expected that you will use some mathematical notation here. If you do please ensure that all notation is explained. You may also want to discuss any special (hypothetical) cases of your model here, as well as any caveats.  

**  

Now, we are going to fit a multiple linear regression model in order to find linear associations between satisfaction_score and other predictor variables: self_rated_health, self_rated_mental_health, family_income, and work_hours.  

Note, the equation for our regression line looks like this:  

satisfaction_score = $\hat{B_0}\ +\ \hat{B_1}*x_{health2}\ +\ \hat{B_2}*x_{health3}\ +\ \hat{B_3}*x_{health4}\ +\ \hat{B_4}*x_{health5}\ +\ \hat{B_5}*x_{mental2}\ +$  
$\hat{B_6}*x_{mental3}\ +\ \hat{B_7}*x_{mental4}\ +\ \hat{B_8}*x_{mental5}\ +\ \hat{B_9}*x_{income2}\ +\ \hat{B_{10}}*x_{income3}\ +\ \hat{B_{11}}*x_{income4}\ +$   
$\hat{B_{12}}*x_{income5}\ +\ \hat{B_{13}}*x_{income6}\ +\ \hat{B_{14}}*x_{work2}\ +\ \hat{B_{15}}*x_{work3}\ +\ \hat{B_{16}}*x_{work4}\ +\ \hat{B_{17}}*x_{work5}$


(The detailed descriptions on the x-variables are found in the footnote^[* $x_{health_{i}}$ is a physical health rating indicator for i from 2 to 5  
\   \   \ (i.e. $x_{health_{5}} = 1$ if the respondent's self_rated_health = 5, and $x_{health_{5}} = 0$ otherwise).  
\   \   \ * $x_{mental_{i}}$ is a mental health rating indicator for i from 2 to 5.  
\   \   \ * $x_{income_{i}}$ is an average income range indicator for i from 2 to 6  
\   \   \ (i.e. $x_{income_{2}} = 1$ if the family income is in the second category "\$25,000 to \$49,999", and $x_{income_{2}}\ =\ 0$ otherwise).  
\   \   \ * $x_{work_{i}}$ is a working hours range indicator for i from 2 to 5  
\   \   \ (i.e. $x_{work_{2}} = 1$ if the average hours of work is in the second category "0.1 to 29.9 hours", and $x_{work_{2}}\ =\ 0$ otherwise).].)

As it is shown above, we are going to have a very long equation for our regression line; however, this is inevitable since each of our predictor variables has several levels in them.

One thing we should notice in our data is that both the income and work_hours variables are categorical. To be more specific, we are given a range of values instead of an exact amount as income or average work hours in each variable. 
However, since our response variable is numerical, and we want to determine if each predictor has a linear relationship with it, we are going to treat our observations in both income and work_hours as numbers by replacing each category in income and work_hours with the midpoint. 

This process will allow us to investigate the linear relationships between the life satisfaction and the two predictors numerically; however, there is a chance where the true values for income or work_hours could be very different from the midpoint. Therefore, we need to take into account when interpreting the regression model, that the two predictor variables could be biased and so does the result.  

```{r include = F, echo = F, warning = F, message= F}
# replace each category in income with its midpoint
model_data <- life_satisfaction_data %>% 
  mutate(family_income = case_when(family_income == "$125,000 and more" ~ 125000.00, 
                                   family_income == "$100,000 to $ 124,999" ~ 112499.50, 
                                   family_income == "$75,000 to $99,999" ~ 87499.50, 
                                   family_income == "$50,000 to $74,999" ~ 62499.50, 
                                   family_income == "$25,000 to $49,999" ~37499.50, 
                                   family_income == "Less than $25,000" ~ 12500.00)) %>%
# replace each category in work_hours with its midpoint
  mutate(work_hours = case_when(work_hours == "0 hour" ~ 0,
                                work_hours == "0.1 to 29.9 hours" ~ 15.0,
                                work_hours == "30.0 to 40.0 hours" ~ 35.0,
                                work_hours == "40.1 to 50.0 hours" ~ 45.05,
                                work_hours == "50.1 hours and more" ~ 50.1))

# General Linear Regression Model
# for satisfaction_score by all predictor variables
satisfaction_lm <- lm(satisfaction_score ~ as.factor(self_rated_health) 
                      + as.factor(self_rated_mental_health) 
                      + as.factor(family_income)
                      + as.factor(work_hours), data = model_data)
```

After finding some relationships between our response and predictor variables using the regression model, we are going to identify which predictor is the most significant factor in explaining the variability in the response variable.
In other words, we are going to find out which of the potential factors (among physical health condition, mental health condition, income and average work hours) can explain the variability in life satisfaction the most.

## Results

*Here you will include all results. This includes descriptive statistics, graphs, figures, tables, and model results. Please ensure that everything is well formatted and in a report style. You must also provide an explanation of the results in this section. You can overflow to an Appendix if needed. Please ensure that everything is well labelled. So if you have multiple histograms and plots, calling them Figure 1, 2, 3, etc. and referencing them as Figure 1, Figure 2, etc. in your report will be expected. The reader should not get lost in a sea of information. Make sure to have the results be clean, well formatted and digestible.*

Here is the summary of the multiple linear regression model:  
###summary1
```{r echo = F, warning = F, message = F}
summary(satisfaction_lm)
```

With the estimates from the regression output, we know that our regression line has a following equation:  

Satisfaction Score $= 3.44552\ +\ 0.51471*x_{health2}\ +\ 0.83475*x_{health3}\ +$   $0.98584*x_{health4}\ +\ 1.17522*x_{health5}\ +\ 1.63274*x_{mental2} +$   $2.69951*x_{mental3}\ +\ 3.24499*x_{mental4}\ +\ 3.72145*x_{mental5}\ +$   $0.11351*x_{income2}\ +\ 0.33408*x_{income3}\ +\ 0.35903*x_{income4}\ +$   $0.47951*x_{income5}\ +\ 0.52816*x_{income6}\ +\ 0.29608*x_{work1}\ +$   $0.23252*x_{work2}\ +\ 0.32056*x_{work3}\ +\ 0.39476*x_{work4}$  

(*Note, you can find the descriptions for  x-variables from the footnotes in the previous page.) 

As we can observe from the output, estimated satisfaction_score increases as each of self_rated_health, self_rated_mental_health and family_income increases; however, the slope estimates for work_hours are found to be quite inconsistent, because there is a decrease in slope estimates from 0.29608 to 0.23252 in the first two categories of work_hours, but they increase again in the third and fourth categories.  
Furthermore, unlike self_rated_health, self_rated_mental_health, and family_income where the p-values are much less than the significance level of 0.05, p-values of work_hours are greater than 0.05; this finding provides us with more evidence that there is no linear relationship between the average working hours and the life satisfaction score. 

Hence, the regression model suggests that only the physical health, mental health and financial conditions have positive linear relationships with the life satisfaction score.  

Now that we've found that the life satisfaction score has linear relationships with physical health, mental health, and financial conditions, we want to ask ourselves: are those factors equally important in terms of explaining the variability in satisfaction_score?  

The answer is 'No'.  

Although they all have positive linear relationships with the response variable, not all variables may contribute significantly in explaining the variability of the response variable.  
Hence, we would now like to identify the most important predictor variable in this regression model. 

There are two ways to do this^[One way is to compare the standardized regression coefficients, and the other way is to compare the increases in adjusted $R^2$ when each predictor is added to the regression model. For this analysis, specifically, we cannot use the first method, because our model contains categorical predictor variable which cannot be standardized.].
In this analysis, specifically, we are going to use the method where we compute and compare the changes in adjusted $R^2$ for the last variable added to the model^[$R^2_{adjusted}\ =\ 1-(1-R^2)*(\frac{n-1}{n-p-1})$ where n is the total sample size and p is the number of additional predictor variables. Hence, unlike $R^2$ that will be inflated as a new predictor is added to the model, regardless of its significance, if the newly added predictor does not explain variation in the response variable well, $R^2_{adjusted}$ will go down.]. This is a valid method for identifying which predictor explains the most variability in the response variable, because by the definition, $R^2$ gives the percentage of variation in the response variable explained by the regression line, and also, if the newly added predictor variable is the only difference between the two models, the associated change in 'adjusted $R^2$' will represent the 'goodness-of-fit'.  

We are going to begin with fitting a linear model with only one predictor, and then add another predictor to the model at a time to see how much $R^2_{adjusted}$ changes when each variable is added.

Key point in this method is to identify the predictor variable with the largest increase in $R^2_{adjusted}$ when it is the last variable added to the model.  

```{r include = F, echo = F, warning = F, message = F}
# Simple Linear Regression Model with predictor self_rated_health
first <- lm(satisfaction_score ~ self_rated_health, data = life_satisfaction_data)
# adjusted R-squared of the first model
first_R2 <- summary(first)$adj.r.squared

# self_rated_mental_health added to the first model
second <- lm(satisfaction_score ~ self_rated_health + self_rated_mental_health, data = life_satisfaction_data)
# adjusted R-squared of the second model
second_R2 <-summary(second)$adj.r.squared

# family_income added to the second model
third <- lm(satisfaction_score ~ self_rated_health + self_rated_mental_health + family_income, data = life_satisfaction_data)
# adjusted R-squared of the last model
third_R2 <- summary(third)$adj.r.squared
```

This is the table with $R^2_{adjusted}$ values in each model, and the change in $R^2_{adjusted}$ as more variables are added:  
## table1
```{r echo = F, warning = F, message = F}
tibble(Predictors = c("self_rated_health", "self_rated_health + self_rated_mental_health", "self_rated_health + self_rated_mental_health + family_income"), R_squared_adjusted = c(first_R2, second_R2, third_R2), Change = c(first_R2, second_R2 - first_R2, third_R2 - second_R2))
```

As it is shown in the table, there is a greatest increase in $R^2_{adjusted}$ when the second predictor, self_rated_mental_health is added to the model. This increase is quite close the $R^2_{adjusted}$ of our initial simple linear regression model with a predictor, self_rated_health.

On the other hand, the change in $R^2_{adjusted}$ is relatively small when family_income is added to the regression model compared to the previous changes, and therefore, we know that the family income does not contribute significantly in explaining the variation in the satisfaction score.

## Discussion
*Here you will discuss conclusions drawn from the results and comment on how it relates to the original goal of the study (which was specified in the Introduction).*


The goal of this process is to find what are some factors that affects and has big influence on person's satisfaction of their lives. 

Graphical visualization of positive correlation of the mental health and life satisfaction score:

```{r echo = F, warning = F, message = F}

life_satisfaction_data %>%
  ggplot(aes(x = as.factor(self_rated_mental_health), y = (satisfaction_score))) + geom_boxplot() +
  ggtitle("Figure 1. Boxplot of Satisfaction score Vs. Self Rated Mental Health") +
  ylab("Satisfaction Score") +
  xlab("Self Rated Mental Health")

life_satisfaction_data %>%
  ggplot(aes(x = as.factor(work_hours), y = (satisfaction_score))) + geom_boxplot() +
  ggtitle("Figure 2. Boxplot of Satisfaction score Vs. Work hours ") +
  ylab("Satisfaction Score") +
  xlab("Work Hours")

```
In Figure 1, The boxplot has a positive linear relationship between the two variables(mental health and life satisfaction). It signifies that average of life satisfaction score increases as the self rated mental health increases. 

Figure 2 shown above is the boxplot of satisfaction score and work hour. the work hour variable includes 0 hour to 50 hours and more, which means that both unemployed and employed are included in this category. The median of 0 hour (unemployed) it's median satisfaction score lower than 0 to 50 hours(employed). But as it was mentioned previously, employed hours show no positive or negative relation with the satisfaction score signifying that there is no significance relationship with satisfaction score.

From Table 1 and Summary 1 in the result section, we find that physical health also has a significant positive linear relationship (using estimates and p-value, and r-squared). so we find physical and mental health are two major factors that affect life satisfaction, however there is no strong relationship shown between income, hours worked and life satisfaction(from summary 1 using p-values and estimates). Hence, the result suggests that both physical and mental health are significant predictors, however, mental health is a more important factor than physical health in terms of explaining the variability of the life satisfaction score.





# Weaknesses

*Here we discuss weaknesses of the study, data, analysis, etc. You can also discuss areas for improvement.*

*Woolim
- Every statistic data study and analysis includes some bias and weaknesses. One of our weakness is that the predictor variables are categorical variable, which made it challenging to visualize the linear regressions model we found and show the significance between the life satisfaction score and other factors. 

- there might be omitted variable bias? 
- but the normal QQ plot shows some downside of the distribution(?)
```{r}
mod<- lm(satisfaction_score ~ self_rated_mental_health, data = life_satisfaction_data)
#plot(mod)
X <- resid(mod)
qqnorm(X)
qqline(X, col = 'red')
```
The normal QQ plot shown above graphically analyze and compare two probability distributions by plotting their quantiles against each other. The bottom end of the Q-Q plot doesn't show a straight line. The distribution has a longer tail to its left which can be interpreted as a left-skewed model.
Normality is one of the assumptions in the linear regression model. However, normality of errors at each value by looking at QQ plot, the deviations from the straight line are huge which doesn't indicate normal distribution. Since the model does not satisfy the assumption, it is considered as a weakness. 


# Next Steps

*Here you discuss subsequent work to be done after this report. This can include next steps in terms of statistical analysis (perhaps there is a more efficient algorithm available, or perhaps there is a caveat in the data that would allow for some new technique). Future steps should also be specified in terms of the study setting (eg. including a follow-up survey on something, or a subsequent study that would complement the conclusions of your report).*

For the next steps, we could do a follow up survey on the related topic (life satisfaction vs mental and physical health), and compare the data of the prior and post COVID-19. We could see how people's mental health changed due to COVID-19, the life satisfaction rate is expected to decrease in this case. Also, we could seek for interaction effects between few independent variables and do ANOVA tests to figure out if there is any independant variable that is dependent to another independant variable. (ie) how age and mental health rate could be interactive).

- look for other factors that affect life satisfaction rate. (maybe focus on households, family, geographical data, etc)

- 


## References

1. GSS Data: 
General Social Survey, Cycle 31: 2017: Family. (n.d.). Retrieved October 16, 2020, from https://sda-artsci-utoronto-ca.myaccess.library.utoronto.ca/cgi-bin/sda/hsda?harcsda4+gss31

2. Data Cleaning Code: 
Alexander, Rohan, and Sam Caetano.( 2019, Sept 16). "gss_cleaning.R”. Retrieved Oct 10. 2020, from
https://www.tellingstorieswithdata.com/01-03-r_essentials.html

3. Identifying the most significant predictor: 
Frost, J., Adusei, C., Peeyush, Siyabonga, Sreeja, Narayanan, J., . . . Sachin. (2019, June 13). Identifying the Most Important Independent Variables in Regression Models. Retrieved October 16, 2020, from https://statisticsbyjim.com/regression/identifying-important-independent-variables/






